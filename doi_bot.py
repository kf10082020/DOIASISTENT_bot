import os
import logging
import requests
from bs4 import BeautifulSoup
from telegram import Update, InlineKeyboardButton, InlineKeyboardMarkup
from telegram.ext import Application, CommandHandler, MessageHandler, filters, CallbackContext

# –ó–∞–º–µ–Ω–∏—Ç—å –Ω–∞ —Å–≤–æ–π —Ç–æ–∫–µ–Ω
TOKEN = os.getenv("TOKEN") or "7822435522:AAH-ZTQuCCxSr385076vyljKLwO8k5Un3DU"

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–æ–≤
logging.basicConfig(format="%(asctime)s - %(name)s - %(levelname)s - %(message)s", level=logging.INFO)
logger = logging.getLogger(__name__)

# === –§–£–ù–ö–¶–ò–Ø 1 === –ü–û–õ–£–ß–ï–ù–ò–ï –ú–ï–¢–ê–î–ê–ù–ù–´–• –ò–ó CROSSREF ===
def fetch_metadata_from_crossref(doi: str):
    url = f"https://api.crossref.org/works/{doi}"
    headers = {"Accept": "application/json"}
    try:
        response = requests.get(url, headers=headers, timeout=10)
        if response.status_code == 200:
            return response.json()
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ Crossref: {e}")
    return None

# === –§–£–ù–ö–¶–ò–Ø 2 === –ü–ê–†–°–ò–ù–ì HTML-–ö–ê–†–¢–û–ß–ö–ò –ü–£–ë–õ–ò–ö–ê–¶–ò–ò (—Ä–µ–∑–µ—Ä–≤–Ω—ã–π –ø—É—Ç—å) ===
def fetch_metadata_from_html(doi_url: str):
    try:
        res = requests.get(doi_url, timeout=10)
        soup = BeautifulSoup(res.text, 'html.parser')
        title = soup.find("meta", attrs={"name": "citation_title"})
        authors = soup.find_all("meta", attrs={"name": "citation_author"})
        year = soup.find("meta", attrs={"name": "citation_publication_date"})
        journal = soup.find("meta", attrs={"name": "citation_journal_title"})
        pages = soup.find("meta", attrs={"name": "citation_firstpage"})

        return {
            "title": title["content"] if title else "‚Äî",
            "authors": [a["content"] for a in authors] if authors else [],
            "year": year["content"] if year else "‚Äî",
            "journal": journal["content"] if journal else "‚Äî",
            "pages": pages["content"] if pages else "‚Äî",
            "download_link": doi_url
        }
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ HTML-–ø–∞—Ä—Å–∏–Ω–≥–µ: {e}")
        return None

# === –§–û–†–ú–ò–†–û–í–ê–ù–ò–ï –†–ï–°–ü–û–ù–°–ê ===
import re

def clean_html(text):
    return re.sub('<[^<]+?>', '', text)

def build_reply(data):
    title    = data.get("title", ["‚Äì"])[0]
    authors  = ", ".join([a.get("family", "") for a in data.get("author", [])])
    issued   = data.get("issued", {}).get("date-parts", [[None]])[0][0] or "‚Äî"
    journal  = data.get("container-title", ["‚Äì"])[0]
    volume   = data.get("volume", "‚Äì")
    issue    = data.get("issue", "‚Äì")
    pages    = data.get("page", "‚Äì")
    url      = data.get("URL", "‚Äì")
    abstract = data.get("abstract", "‚Äî")
    abstract_clean = clean_html(abstract)
    abstract_ru = "–ø–µ—Ä–µ–≤–æ–¥ –≤—Ä–µ–º–µ–Ω–Ω–æ –æ—Ç–∫–ª—é—á–µ–Ω"

    text = (
        f"*üìò –ù–∞–∑–≤–∞–Ω–∏–µ:* {title}\n"
        f"*‚úçÔ∏è –ê–≤—Ç–æ—Ä—ã:* {authors}\n"
        f"*üìÖ –ì–æ–¥:* {issued}\n"
        f"*üèõ –ñ—É—Ä–Ω–∞–ª:* {journal}\n"
        f"*üìë –¢–æ–º / –í—ã–ø—É—Å–∫ / –°—Ç—Ä–∞–Ω–∏—Ü—ã:* {volume} / {issue} / {pages}\n"
        f"*üîó DOI / URL:* {url}\n\n"
        f"*üìù –ê–Ω–Ω–æ—Ç–∞—Ü–∏—è:* {abstract_clean[:500]}...\n"
        f"*üîÑ –ü–µ—Ä–µ–≤–æ–¥:* {abstract_ru}"
    )
    return text
        )
    else:
        return (
            f"üìñ *–ù–∞–∑–≤–∞–Ω–∏–µ:* {data['title']}\n"
            f"üë®‚Äçüî¨ *–ê–≤—Ç–æ—Ä—ã:* {', '.join(data['authors']) or '‚Äî'}\n"
            f"üìÖ *–ì–æ–¥:* {data['year']}\n"
            f"üìö *–ñ—É—Ä–Ω–∞–ª:* {data['journal']}\n"
            f"üìÑ *–°—Ç—Ä–∞–Ω–∏—Ü—ã:* {data['pages']}\n"
            f"üîó *–°—Å—ã–ª–∫–∞:* {data['download_link']}"
        )

# === –û–ë–†–ê–ë–û–¢–ß–ò–ö –°–û–û–ë–©–ï–ù–ò–ô –° DOI ===
async def handle_doi(update: Update, context: CallbackContext):
    doi_url = update.message.text.strip()
    if "doi.org/" not in doi_url:
        await update.message.reply_text("‚ùó –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –æ—Ç–ø—Ä–∞–≤—å—Ç–µ —Å—Å—ã–ª–∫—É –≤–∏–¥–∞ `https://doi.org/...`")
        return

    doi = doi_url.split("doi.org/")[-1]
    metadata = fetch_metadata_from_crossref(doi)

    if metadata:
        response = build_response(metadata)
    else:
        fallback_data = fetch_metadata_from_html(doi_url)
        if fallback_data:
            response = build_response(fallback_data)
        else:
            response = "‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –ø–æ —Å—Å—ã–ª–∫–µ."

    await update.message.reply_text(response, parse_mode="Markdown")

# === –°–¢–ê–†–¢ –ö–û–ú–ê–ù–î–ê ===
async def start(update: Update, context: CallbackContext):
    await update.message.reply_text("–ü—Ä–∏–≤–µ—Ç! –û—Ç–ø—Ä–∞–≤—å—Ç–µ –º–Ω–µ DOI —Å—Ç–∞—Ç—å–∏, –∏ —è –Ω–∞–π–¥—É –ø–æ –Ω–µ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é.")

# === –û–°–ù–û–í–ù–û–ô –¶–ò–ö–õ ===
def main():
    app = Application.builder().token(TOKEN).build()
    app.add_handler(CommandHandler("start", start))
    app.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, handle_doi))
    app.run_polling()

if __name__ == "__main__":
    main()
