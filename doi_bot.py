import requests
from bs4 import BeautifulSoup
import re

# === Ğ˜Ğ¡Ğ¢ĞĞ§ĞĞ˜ĞšĞ˜ ĞœĞ•Ğ¢ĞĞ”ĞĞĞĞ«Ğ¥ ===

def fetch_metadata_crossref(doi):
    try:
        url = f"https://api.crossref.org/works/{doi}"
        r = requests.get(url, timeout=10)
        r.raise_for_status()
        return r.json()["message"]
    except Exception:
        return None

def fetch_metadata_pubmed(doi):
    try:
        query = f"https://eutils.ncbi.nlm.nih.gov/entrez/eutils/esearch.fcgi?db=pubmed&term={doi}&retmode=json"
        r = requests.get(query, timeout=10)
        r.raise_for_status()
        pmid = r.json()["esearchresult"]["idlist"][0]

        fetch = f"https://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi?db=pubmed&id={pmid}&retmode=xml"
        r = requests.get(fetch, timeout=10)
        soup = BeautifulSoup(r.content, "xml")
        return {
            "title": soup.find("ArticleTitle").text,
            "authors": [x.text for x in soup.find_all("LastName")],
            "journal": soup.find("Title").text,
            "issued": soup.find("PubDate").text,
            "abstract": soup.find("AbstractText").text,
            "volume": None,
            "issue": None,
            "pages": None,
            "pdf_url": None
        }
    except Exception:
        return None

def fetch_metadata_html(doi_url):
    try:
        headers = {"User-Agent": "Mozilla/5.0"}
        r = requests.get(doi_url, headers=headers, timeout=10)
        r.raise_for_status()
        soup = BeautifulSoup(r.text, "html.parser")

        def meta(name):
            tag = soup.find("meta", {"name": name})
            return tag["content"] if tag else None

        return {
            "title": meta("citation_title"),
            "authors": meta("citation_author"),
            "journal": meta("citation_journal_title"),
            "issued": meta("citation_publication_date"),
            "volume": meta("citation_volume"),
            "issue": meta("citation_issue"),
            "pages": meta("citation_firstpage"),
            "abstract": meta("description") or meta("citation_abstract"),
            "pdf_url": meta("citation_pdf_url")
        }
    except Exception:
        return None

# === ĞĞ‘Ğ ĞĞ‘ĞĞ¢Ğ§Ğ˜Ğš Ğ Ğ•Ğ—Ğ£Ğ›Ğ¬Ğ¢ĞĞ¢Ğ ===

def build_reply(data):
    if not data:
        return "âŒ ĞĞµ ÑƒĞ´Ğ°Ğ»Ğ¾ÑÑŒ Ğ¸Ğ·Ğ²Ğ»ĞµÑ‡ÑŒ Ğ¼ĞµÑ‚Ğ°Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ."

    authors = ", ".join(data.get("authors", [])) if isinstance(data.get("authors"), list) else data.get("authors", "â€”")

    reply = f"ğŸ“˜ *ĞĞ°Ğ·Ğ²Ğ°Ğ½Ğ¸Ğµ:* {data.get('title', 'â€”')}\n"
    reply += f"ğŸ‘¨â€ğŸ”¬ *ĞĞ²Ñ‚Ğ¾Ñ€Ñ‹:* {authors}\n"
    reply += f"ğŸ“… *Ğ“Ğ¾Ğ´:* {data.get('issued', 'â€”')}\n"
    reply += f"ğŸ“š *Ğ–ÑƒÑ€Ğ½Ğ°Ğ»:* {data.get('journal', 'â€”')}\n"
    reply += f"ğŸ“¦ *Ğ¢Ğ¾Ğ¼:* {data.get('volume', 'â€”')}\n"
    reply += f"ğŸ“ *Ğ’Ñ‹Ğ¿ÑƒÑĞº:* {data.get('issue', 'â€”')}\n"
    reply += f"ğŸ“„ *Ğ¡Ñ‚Ñ€Ğ°Ğ½Ğ¸Ñ†Ñ‹:* {data.get('pages', 'â€”')}\n"
    reply += f"\nğŸ“ *ĞĞ½Ğ½Ğ¾Ñ‚Ğ°Ñ†Ğ¸Ñ:*\n{data.get('abstract', 'ĞĞµÑ‚ Ğ°Ğ½Ğ½Ğ¾Ñ‚Ğ°Ñ†Ğ¸Ğ¸')}\n"

    if data.get("pdf_url"):
        reply += f"\nğŸ“¥ *PDF:* [Ğ¡ĞºĞ°Ñ‡Ğ°Ñ‚ÑŒ PDF]({data['pdf_url']})\n"

    return reply

# === ĞĞ¡ĞĞĞ’ĞĞĞ¯ Ğ¤Ğ£ĞĞšĞ¦Ğ˜Ğ¯ ===

def handle_doi(doi_url):
    doi = re.findall(r"10\.\d{4,9}/[-._;()/:A-Z0-9]+", doi_url, re.I)
    if not doi:
        return "âŒ DOI Ğ½Ğµ Ñ€Ğ°ÑĞ¿Ğ¾Ğ·Ğ½Ğ°Ğ½."
    doi = doi[0]

    for fetcher in [fetch_metadata_crossref, fetch_metadata_pubmed, fetch_metadata_html]:
        data = fetcher(doi if fetcher != fetch_metadata_html else doi_url)
        if data:
            return build_reply(data)

    return "âŒ ĞĞµ ÑƒĞ´Ğ°Ğ»Ğ¾ÑÑŒ Ğ½Ğ°Ğ¹Ñ‚Ğ¸ Ğ¿ÑƒĞ±Ğ»Ğ¸ĞºĞ°Ñ†Ğ¸Ñ Ğ¿Ğ¾ DOI."

# === ĞŸÑ€Ğ¸Ğ¼ĞµÑ€ Ğ·Ğ°Ğ¿ÑƒÑĞºĞ° ===

if __name__ == "__main__":
    sample_doi_url = "https://doi.org/10.1080/10811680.2024.2384356"
    print(handle_doi(sample_doi_url))
