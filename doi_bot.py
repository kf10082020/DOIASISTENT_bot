import os
import re
import requests
from urllib.parse import urlparse
from dotenv import load_dotenv
from telegram import Update
from telegram.ext import ApplicationBuilder, MessageHandler, CommandHandler, filters, ContextTypes

# –ó–∞–≥—Ä—É–∂–∞–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ —Å—Ä–µ–¥—ã
load_dotenv()
BOT_TOKEN = os.getenv("TELEGRAM_BOT_TOKEN")
if not BOT_TOKEN:
    raise RuntimeError("‚ùå –û—à–∏–±–∫–∞: TELEGRAM_BOT_TOKEN –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –≤ .env")

# –ü–∞—Ä—Å–µ—Ä—ã –¥–ª—è —Å–∞–π—Ç–æ–≤
def parse_mdpi(doi): return requests.get(f"https://api.crossref.org/works/{doi}").json()['message']
def parse_springer(doi): return requests.get(f"https://api.crossref.org/works/{doi}").json()['message']
def parse_sciencedirect(doi): return requests.get(f"https://api.crossref.org/works/{doi}").json()['message']
def parse_pubmed(doi): return requests.get(f"https://api.crossref.org/works/{doi}").json()['message']
def parse_wiley(doi): return requests.get(f"https://api.crossref.org/works/{doi}").json()['message']
def parse_ssrn(doi): return requests.get(f"https://api.crossref.org/works/{doi}").json()['message']

site_parsers = {
    "www.mdpi.com": parse_mdpi,
    "link.springer.com": parse_springer,
    "www.sciencedirect.com": parse_sciencedirect,
    "pubmed.ncbi.nlm.nih.gov": parse_pubmed,
    "onlinelibrary.wiley.com": parse_wiley,
    "www.ssrn.com": parse_ssrn,
}

def extract_doi(text: str):
    match = re.findall(r"10\.\d{4,9}/[-._;()/:A-Z0-9]+", text, re.I)
    return match[0] if match else None

def get_domain_from_doi(doi: str):
    try:
        url = requests.get(f"https://doi.org/{doi}", allow_redirects=True, timeout=10).url
        return urlparse(url).netloc
    except Exception:
        return None

def fetch_metadata(doi: str):
    domain = get_domain_from_doi(doi)
    if domain in site_parsers:
        return site_parsers[domain](doi)
    else:
        # fallback —á–µ—Ä–µ–∑ CrossRef
        return requests.get(f"https://api.crossref.org/works/{doi}").json()['message']

async def handle_message(update: Update, context: ContextTypes.DEFAULT_TYPE):
    text = update.message.text
    doi = extract_doi(text)
    if not doi:
        await update.message.reply_text("‚ùå DOI –Ω–µ –Ω–∞–π–¥–µ–Ω.")
        return

    try:
        data = fetch_metadata(doi)
    except Exception as e:
        await update.message.reply_text(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ –¥–∞–Ω–Ω—ã—Ö: {e}")
        return

    title = data.get("title", ["‚Äî"])[0]
    authors = ", ".join([f"{a.get('family', '')} {a.get('given', '')}" for a in data.get("author", [])]) or "‚Äî"
    journal = data.get("container-title", ["‚Äî"])[0]
    year = data.get("published-print", {}).get("date-parts", [[None]])[0][0] or data.get("issued", {}).get("date-parts", [[None]])[0][0]

    msg = f"""üìò *{title}*
üë®‚Äçüî¨ *–ê–≤—Ç–æ—Ä—ã:* {authors}
üìö *–ñ—É—Ä–Ω–∞–ª:* {journal}
üìÖ *–ì–æ–¥:* {year}
üîó *DOI:* https://doi.org/{doi}
"""
    await update.message.reply_markdown(msg)

async def start(update: Update, context: ContextTypes.DEFAULT_TYPE):
    await update.message.reply_text("üëã –û—Ç–ø—Ä–∞–≤—å—Ç–µ DOI-—Å—Å—ã–ª–∫—É, –∏ —è –Ω–∞–π–¥—É –ø—É–±–ª–∏–∫–∞—Ü–∏—é.")

def main():
    app = ApplicationBuilder().token(BOT_TOKEN).build()
    app.add_handler(CommandHandler("start", start))
    app.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, handle_message))
    app.run_polling()

if __name__ == "__main__":
    main()
