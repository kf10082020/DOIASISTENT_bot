import os
import logging
import re
import requests
from bs4 import BeautifulSoup
from telegram import Update
from telegram.ext import CallbackQueryHandler

async def handle_button(update: Update, context: ContextTypes.DEFAULT_TYPE):
    query = update.callback_query
    await query.answer()

    if query.data == "publish_article":
        await query.edit_message_text(
            text="üîî –°—Å—ã–ª–∫–∞ –Ω–∞ –ø—É–±–ª–∏–∫–∞—Ü–∏—é –≤–∞—à–µ–≥–æ –Ω–∞—É—á–Ω–æ–≥–æ —Ç—Ä—É–¥–∞: [–û—Ç–∫—Ä—ã—Ç—å —Ñ–æ—Ä–º—É](https://your-platform.com/publish)",
            parse_mode="Markdown"
        )

app.add_handler(CallbackQueryHandler(handle_button))

from telegram.ext import ApplicationBuilder, CommandHandler, MessageHandler, ContextTypes, filters

# --- –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ ---
logging.basicConfig(format='%(asctime)s - %(name)s - %(levelname)s - %(message)s', level=logging.INFO)
logger = logging.getLogger(__name__)

# --- –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ ---
def fetch_metadata_crossref(doi):
    try:
        r = requests.get(f"https://api.crossref.org/works/{doi}", timeout=10)
        r.raise_for_status()
        return r.json()["message"]
    except:
        return None

def fetch_metadata_pubmed(doi):
    try:
        search_url = f"https://eutils.ncbi.nlm.nih.gov/entrez/eutils/esearch.fcgi?db=pubmed&term={doi}&retmode=json"
        r = requests.get(search_url, timeout=10)
        pmid = r.json()["esearchresult"]["idlist"][0]
        fetch_url = f"https://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi?db=pubmed&id={pmid}&retmode=xml"
        soup = BeautifulSoup(requests.get(fetch_url).content, "xml")
        return {
            "title": soup.find("ArticleTitle").text,
            "authors": [x.text for x in soup.find_all("LastName")],
            "journal": soup.find("Title").text,
            "issued": soup.find("PubDate").text,
            "abstract": soup.find("AbstractText").text
        }
    except:
        return None

def fetch_metadata_html(doi_url):
    try:
        r = requests.get(doi_url, headers={"User-Agent": "Mozilla/5.0"}, timeout=10)
        soup = BeautifulSoup(r.text, "html.parser")
        meta = lambda name: soup.find("meta", {"name": name})
        get = lambda name: meta(name)["content"] if meta(name) else None
        return {
            "title": get("citation_title"),
            "authors": get("citation_author"),
            "journal": get("citation_journal_title"),
            "issued": get("citation_publication_date"),
            "volume": get("citation_volume"),
            "issue": get("citation_issue"),
            "pages": get("citation_firstpage"),
            "abstract": get("description"),
            "pdf_url": get("citation_pdf_url")
        }
    except:
        return None

def build_reply(data):
    if not data:
        return "‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ."
    authors = ", ".join(data.get("authors", [])) if isinstance(data.get("authors"), list) else data.get("authors", "‚Äî")
    reply = f"üìò *–ù–∞–∑–≤–∞–Ω–∏–µ:* {data.get('title', '‚Äî')}\n"
    reply += f"üë®\u200düî¨ *–ê–≤—Ç–æ—Ä—ã:* {authors}\n"
    reply += f"üìÖ *–ì–æ–¥:* {data.get('issued', '‚Äî')}\n"
    reply += f"üìö *–ñ—É—Ä–Ω–∞–ª:* {data.get('journal', '‚Äî')}\n"
    reply += f"üì¶ *–¢–æ–º:* {data.get('volume', '‚Äî')}\n"
    reply += f"üìé *–í—ã–ø—É—Å–∫:* {data.get('issue', '‚Äî')}\n"
    reply += f"üìÑ *–°—Ç—Ä–∞–Ω–∏—Ü—ã:* {data.get('pages', '‚Äî')}\n"
    reply += f"\nüìù *–ê–Ω–Ω–æ—Ç–∞—Ü–∏—è:*\n{data.get('abstract', '–∞–Ω–æ—Ç–∞—Ü–∏—è –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ' '–ù–µ—Ç –∞–Ω–Ω–æ—Ç–∞—Ü–∏–∏')}\n"
    if data.get("pdf_url"):
        reply += f"\nüì• *PDF:* [–°–∫–∞—á–∞—Ç—å PDF]({data['pdf_url']})\n"
    return reply

def extract_doi(text):
    match = re.findall(r"10\.\d{4,9}/[-._;()/:A-Z0-9]+", text, re.I)
    return match[0] if match else None

# --- Telegram Handlers ---
async def start(update: Update, context: ContextTypes.DEFAULT_TYPE):
    await update.message.reply_text("–î–æ–±—Ä—ã–π –¥–µ–Ω—å! –û—Ç–ø—Ä–∞–≤—å –º–Ω–µ DOI-—Å—Å—ã–ª–∫—É, –∏ —è –≤—ã–≤–µ–¥—É –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ —Å—Ç–∞—Ç—å–∏.")

async def handle_message(update: Update, context: ContextTypes.DEFAULT_TYPE):
    text = update.message.text.strip()
    doi = extract_doi(text)
    if not doi:
        await update.message.reply_text("‚ùå DOI –Ω–µ –Ω–∞–π–¥–µ–Ω. –û—Ç–ø—Ä–∞–≤—å –∫–æ—Ä—Ä–µ–∫—Ç–Ω—É—é —Å—Å—ã–ª–∫—É.")
        return

    metadata = handle_doi(doi)
    reply_text, keyboard = format_reply(metadata)
    await update.message.reply_text(reply_text, reply_markup=keyboard, parse_mode="Markdown")

   # --- Main Entry ---
if __name__ == '__main__':
    from dotenv import load_dotenv
    load_dotenv()

    token = os.getenv("TELEGRAM_BOT_TOKEN")
    if not token:
        raise RuntimeError("TELEGRAM_BOT_TOKEN –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –≤ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è.")

    app = ApplicationBuilder().token(token).build()
    app.add_handler(CommandHandler("start", start))
    app.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, handle_message))
    app.run_polling()
